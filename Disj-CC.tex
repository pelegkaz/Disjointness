\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage{paralist}
\usepackage[usenames]{color}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{appendix}
%\usepackage[boxed,vlined]{algorithm2e}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{placeins}
\usepackage{authblk}
\usepackage[normalem]{ulem}
\usepackage[ruled,boxed,vlined]{algorithm2e}
\usepackage{float}
\usepackage[colorlinks,urlcolor=black,citecolor=black,linkcolor=black]{hyperref}

\title{Disjointness CC}
\author{Peleg Kazaz}
\date{August 2019}

\begin{document}

\maketitle


%Special macros
\newcommand{\fnstyle}[1]{\mathsf{#1}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{claim}{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{property}{Property}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}{Definition}
\newtheorem{invariant}{Invariant}
\newtheorem*{remark}{Remark}

\renewcommand{\include}{\input}

\section{Introduction}
We are going to consider a sequential point of view for the disjointness problem for k players. Let us imagine a process in which the players go one after another and intersect their sets with the result. Starting with the full set ($[n]$), after the last player plays, we end up with the intersection of all sets. Therefore our question is whether this set is empty or not. Moreover, if the last set is empty, one of the players must subtract a large amount of elements in this process. After he plays we get a set which is in smaller order of magnitude than the one before. The difference between those sets are included in the player's zeros. That is where we have an option to learn them using small amount of communication. 
\subsection{Related Work}
\section{Preliminaries}
\subsection{Notations}
We use the popular notation: We are going to have $k$ players. For $i \in [k], X_i \in \{0,1\}^{n}$ - the $i$'th player's input. Sometimes we are going to think of $X_i$ as a subset of $[n]$ where $X_i = \{j \in [n] | X_{ij} = 1\}$. In this notation, the distjointness problem is to decide whether $\cap^{k}_{j=1}X_j = \emptyset$. \newline
Let us define the following sets: $A_0 := [n]$, for $i \in [k]$ : $A_i := \cap^{i}_{j=1}X_j ( = A_{i-1} \cap X_i)$. Using this notation, disjointness problem is whether $A_k = \emptyset$ or not. 
\subsection{Properties}
\begin{claim}
Let $i \in [k]$ be the minimal index such that $\frac{|A_{i}|}{|A_{i-1}|} < \frac{1}{n^{1/k}}$. We assume such one exists and name it "the critical index". So for every $j < i$, $|A_j| \geq n^{1-\frac{j}{k}}$
\end{claim}
\begin{proof}
By induction of $j$. Induction basis is for $j = 0$, $A_0 = n$ by definition. The induction step: $j < i$ so $\frac{|A_{j}|}{|A_{j-1}|} \geq \frac{1}{n^{\frac{1}{k}}}$. By induction assumption $|A_{j}| \geq \frac{n^{1-\frac{j-1}{k}}}{n^{1/k}} = n^{1-\frac{j}{k}}$ as needed.
\end{proof}
\begin{claim}
When the sets are disjoint, there is a critical index.
\end{claim}
\begin{proof}
Proof by contradiction.
Let us assume that $\forall_{i\in[k]} \frac{|A_i|}{|A_{i-1}|} \geq \frac{1}{n^{\frac{1}{k}}}$. So we get that: \\
 $\frac{|A_k|}{|A_0|} = \frac{|A_k|}{|A_{k-1}|}\cdot\frac{|A_{k-1}|}{|A_{k-2}|}\cdot...\cdot\frac{|A_2|}{|A_1|}\cdot\frac{|A_1|}{|A_0|} \geq \left (  \frac{1}{n^{\frac{1}{k}}} \right )^k = \frac{1}{n} $ \\
 $ \frac{|A_k|}{n} \geq \frac{1}{n}$ \\
 $ |A_k| \geq 1$ in contradiction to the assumption that the sets are disjoint.
\end{proof}
\section{$O(kn^{1-1/k})$ Protocol}
\subsection{Properties of Our Protocol}
Our protocol is using random coins and is described in the coordinator model. It uses an expected value of $O(kn^{1-1/k})$ bits of communication between the players.
\subsection{The Protocol}
Our protocol is divided into rounds. In each round we find out some zeros of some player and then we ignore these indexes from now on and make our universe smaller. \newline
Every round works like this: \newline
The coordinator asks the players one by one whether $\Pr[DISJ \land \text{i is critical} | X_i = x_i \land \text{We got this far in the protocol}] \geq \frac{\epsilon}{k}$. \newline
If all of them answer negative - declare intersection. \newline
Otherwise, choose the first one to take out indexes by the following protocol: \newline
First the coordinator sends his identity ($i$) to all of the players. \newline
Now all of them parse the public random coins as samples of $A_{i-1}$ (Every player knows to parse it). Player $i$ finds a sample in which he is critical. Then he sends its index to the coordinator and after that he sends $A_i (=A_{i-1} \cap x_i)$ index by index. The coordinator sends this information to every other player.
Note that knowing this information they all can deduce $A_i \setminus A_{i-1} \subseteq X^{c}_i$ which are zeros of player $i$. They all take these zeros out (making the universe smaller $U := U \cap (A_i \setminus A_{i-1})$). If $|U| \leq n^{1-1/k}$, everyone sends their inputs to the coordinator which calculate the answer and declares accordingly.
\subsection{Analysis}
\paragraph{Error Analysis}
For each leaf $L$ in our protocol tree (determined by X,Y), we are going to argue that we error for at most $\epsilon$. Therefore in overall we don't error more than $\epsilon$. (We consider the tree given specific random coins) \newline
A leaf $L$ is a round in which we stop. \newline
The only times we error is when we answer due to the probability calculations. The other leaves have 0 error.\newline
$\Pr[ERROR | \text{Stopped at L}] \overset{(1)}{=} \Pr[ERROR \land DISJ | \text{Stopped at L}] \overset{(2)}{=} \sum\limits_{i=1}^k \Pr[ERROR \land \text{DISJ} \land \text{i is critical}| \text{Stopped at L}] \overset{(3)}{=} \sum\limits_{i=1}^k \underset{X_i=x_i}{\mathop{\mathbb{E}}}\Pr[ERROR \land \text{DISJ}\land \text{i is critical}| \text{Stopped at L} \land X_i=x_i] \leq \sum\limits_{i=1}^k \underset{X_i=x_i}{\mathop{\mathbb{E}}}[\frac{\epsilon}{k}] = \sum\limits_{i=1}^k \frac{\epsilon}{k} = \epsilon$ \newline
\newline
$\Pr[ERROR] = \underset{\text{L leaf}}{\mathop{\mathbb{E}}} [\Pr[ERROR | \text{Stopped at L}] ] \leq \epsilon $ \newline
(1) - The protocol errors only when the sets are disjoint (the protocol declares intersection). \newline
(2) - $  \text{DISJ} = \biguplus_{i=1}^{k}\{DISJ \land \text{i is the critical index} \} $ \newline
(3) - Law of total expectation
\paragraph{Communication Analysis}
We analyze round by round. For a single round, firstly we pay at most $k$ bits in order to find if some player has a chance to have critical index. After that the coordinator sends his identity to the others $k\log(k)$ bits. Then the protocol sends the sample index and $A_{i}$ to all of the players. Now we ask what is the expected value of the index. \newline
This is a random variable which has a geometric distribution. \newline
$ \mathop{\mathbb{E}} [J] = \frac{1}{\Pr[DISJ \land \text{i is critical} | X_i = x_i \land \text{We got this far in the protocol}]} \leq \frac{k}{\epsilon}$ \newline
$\mathop{\mathbb{E}} [\log(J)] \leq \log(\mathop{\mathbb{E}} [J]) \leq \log(\frac{k}{\epsilon}) = \log(k) + \log(\frac{1}{\epsilon})$ \newline
Let us define $m : = |A_i|$ for the chosen $A_i$ for the specific round.
Pay attention that $|A_i| \cdot n^{-1/k} \geq |A_{i-1}| \geq n^{1-\frac{i-1}{k}}$ \newline
$m \geq n^{1-\frac{i}{k}} \geq 1$ so $m \neq 0$\newline
We know that $|A_{i-1}| \geq |A_i| \cdot n^{1/k}$. In this round we discovered that $A_{i-1} \setminus A_i$ are zeros for player i. Pay attention $|A_{i-1} \setminus A_i| \overset{(1)}{=} |A_{i-1}| - |A_i| \geq |A_i|(n^{1/k} - 1) = m(n^{1/k} - 1)$ \newline
So in total the cost of the round is $k + k\log(k) + k(\log(k) + \log(\frac{1}{\epsilon})) + km\log(n)$ and we discovered at least $m(n^{1/k} - 1)$ zeros. \newline
$f(n) = k(\log(k) + \log(\frac{1}{\epsilon}) + m\log(n)) + f(n - m(n^{1/k} - 1))$ \newline 
$f(n) \in O(kn^{1-\frac{1}{k}}\log(n))$ \newline
(1) $A_i \subseteq A_{i-1}$
\section{Extra}
\paragraph{Binary Distribution}
Let us consider a specific interesting distribution for $n = 2^{k-1}$. We think of $X_i \subseteq \{0, 1, ... , n-1\} $ \newline
For $i \in [k-1]$
  \[
    X_i=\left\{
                \begin{array}{ll}
                  \{0 \leq m \leq n-1 \| m_{i-1} = 0\} \text{ w.p 0.5} \\
                  \{0 \leq m \leq n-1 \| m_{i-1} = 1\} \text{ w.p 0.5}
                \end{array}
              \right.
  \]
and for $i = k$
  \[
    X_k=\left\{
                \begin{array}{ll}
                  \{0 \leq m \leq n-1 \| \underset{i=1}{\overset{k-1}{\oplus}} m_i = 0\} \text{ w.p 0.5} \\
                  \{0 \leq m \leq n-1 \| \underset{i=1}{\overset{k-1}{\oplus}} m_i = 1\} \text{ w.p 0.5}
                \end{array}
              \right.
  \]
where $m_i$ is the $i$'th bit of m in binary representation. ($m_i \mathrel{\mathop:}= ( m \mathop{\&} 2^{i-1} ) \gg i-1 $). \\
Let's pay attention for some simple properties. First of all $\forall_i |X_i| = \frac{n}{2}$. Moreover, it doesn't matter if we permute the players, for $i < k, |A_i| = 0.5|A_{i-1}|$ and generally for $i < k, |A_i| = 2^{k-1-i}$. $\Pr[DISJ] = 0.5$. The thing is that this distribution has a little entropy ($k$).
\section{Appendix}
\paragraph{Proof for $f(n) \in O(kn^{1-1/k})$}
\begin{claim} 
For $f(n) = k(\log(k) + \log(\frac{1}{\epsilon}) + m) + f(n - m(n^{1/k} - 1))$, it is true that $f(n) \in O(kn^{1-1/k})$ (when thinking of $\epsilon$ as a constant). \newline
\end{claim}
\begin{proof}
We should find that $ \exists_{D\in\mathbb{R}} : \forall_{n \in \mathbb{N}} : f(n) \leq Dkn^{1-1/k}$. Let us prove by induction. The induction base is trivial (we can choose big enough $D$). The induction step: \newline
We can think of $\epsilon$ as a constant. \newline
$f(n) = k(\log(k) + m) + f(n - m(n^{1/k} - 1)) \leq k(\log(k) + m) + Dk(n - m(n^{1/k} - 1))^{1-1/k} \overset{?}{\leq} Dkn^{1-1/k}$ \newline

\begin{align*}
  k(\log(k) + m) &\overset{?}{\leq} Dkn^{1-1/k} -  Dk(n - m(n^{1/k} - 1))^{1-1/k}\\
  (\log(k) + m) &\overset{?}{\leq} D(n^{1-1/k} -  (n - m(n^{1/k} - 1))^{1-1/k})\\
  \frac{\log(k) + m}{n^{1-1/k} -  (n - m(n^{1/k} - 1))^{1-1/k}} & \overset{?}{\leq} D \\
\end{align*}
\newline
Maybe we can just say that the worse case is when $m = 1$.
In this case we have $n^{1-\frac{1}{k}}$ rounds where each one costs $k\log(k)$ so $kn^{1-\frac{1}{k}}\log(k)$
\end{proof}

\subsection{TODO}
What if m=0? \newline
Tough (est?) distribution\newline
Make sure to rethink how does this protocol end \newline
Does it help to permutate the players? \newline
Do we have to tell every player everything? maybe we can get rid of the k factor? \newline
\end{document}
